{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lH7LBPFJ5fPE"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Sampler, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.io import read_image\n",
        "from torchvision import transforms\n",
        "import torchvision.transforms.functional as tf\n",
        "\n",
        "import cv2\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchtext \n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WH0v2_Dv5om_"
      },
      "outputs": [],
      "source": [
        "torchtext.utils.download_from_url(\"http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/facades.tar.gz\")\n",
        "torchtext.utils.extract_archive(\"./.data/facades.tar.gz\",\"data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YziPAalj6bAf"
      },
      "outputs": [],
      "source": [
        "!ls -al\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kscOOzqK8CRu"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, img_dir, data=\"train\", transform=True):\n",
        "    self.transform = transform\n",
        "    self.img_dir= os.path.join(img_dir, data)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(os.listdir(self.img_dir)) \n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    img_path = os.path.join(self.img_dir, f\"{idx+1}.jpg\")\n",
        "    img = read_image(img_path,torchvision.io.image.ImageReadMode.RGB)\n",
        "    width = img.shape[2]//2\n",
        "    input = img[:,:,width:]\n",
        "    real = img[:,:,:width]\n",
        "    if self.transform:\n",
        "        input, real = self.transform_imgs(input,real,(286,286))\n",
        "    input = (input / 127.5) - 1\n",
        "    real = (real / 127.5) - 1\n",
        "    return input.type('torch.FloatTensor'), real.type('torch.FloatTensor')\n",
        "  \n",
        "  def transform_imgs(self,input, real, resize_dim):\n",
        "    org_dim = (input.shape[1], input.shape[2]) \n",
        "    resize = transforms.Resize(size=resize_dim)\n",
        "    input,real = resize(input), resize(real)\n",
        "    i, j, h, w = transforms.RandomCrop.get_params(input, output_size=org_dim)\n",
        "    input, real = tf.crop(input, i, j, h, w), tf.crop(real, i, j, h, w)\n",
        "    if np.random.rand() > 0.5:\n",
        "        input,real = tf.hflip(input),tf.hflip(real)\n",
        "    return input, real"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhosWZW_Eagd"
      },
      "outputs": [],
      "source": [
        "train_data = CustomDataset(img_dir=\"data/facades\", data=\"val\", transform=True)\n",
        "img, real = train_data[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRIsF98OE7DI"
      },
      "outputs": [],
      "source": [
        "plt.imshow(img.permute(1, 2, 0))\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(real.permute(1, 2, 0))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsgUFvlcaDfH"
      },
      "outputs": [],
      "source": [
        "class DownSampleBlock(nn.Module):\n",
        "  def __init__(self, in_ch, out_ch, use_batchnorm=False, stride=2, padding=1):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_ch, out_ch, 4,stride=stride, padding=padding, bias=False)\n",
        "    nn.init.normal_(self.conv1.weight, mean=0.0, std=0.02)\n",
        "    self.bn = nn.BatchNorm2d(out_ch) if use_batchnorm else None\n",
        "    self.relu  = nn.LeakyReLU()\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    if self.bn:\n",
        "      x = self.bn(x)\n",
        "    x = self.relu(x)\n",
        "    return x\n",
        "\n",
        "class UpSampleBlock(nn.Module):\n",
        "  def __init__(self, in_ch, out_ch, use_dropout=True):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.ConvTranspose2d(in_ch, out_ch, 4,stride=2, padding=1,bias=False)\n",
        "    nn.init.normal_(self.conv1.weight, mean=0.0, std=0.02)\n",
        "    self.bn = nn.BatchNorm2d(out_ch)\n",
        "    self.relu  = nn.ReLU()\n",
        "    self.dropout = nn.Dropout(0.5) if use_dropout else None\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn(x)\n",
        "    if self.dropout:\n",
        "      x = self.dropout(x)\n",
        "    x = self.relu(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYLU8cgXYLD4"
      },
      "outputs": [],
      "source": [
        "print(img.shape)\n",
        "ds = DownSampleBlock(3,3)\n",
        "x = ds(img.float())\n",
        "print(x.shape)\n",
        "ds = UpSampleBlock(3,3)\n",
        "x = ds(x.unsqueeze(0))\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "340B6wNcawuw"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, chs, batch_norm):\n",
        "    super().__init__()\n",
        "    self.enc_blocks = nn.ModuleList([DownSampleBlock(chs[i], chs[i+1],batch_norm[i]) for i in range(len(chs)-1)])\n",
        "  \n",
        "  def forward(self, x):\n",
        "    ftrs = []\n",
        "    for block in self.enc_blocks:\n",
        "        x = block(x)\n",
        "        ftrs.append(x)\n",
        "        # print(x.shape)\n",
        "    return x,ftrs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pd1N08g8hbfw"
      },
      "outputs": [],
      "source": [
        "chs = [3,64,128,256,512,512,512,512,512]\n",
        "bn = [True]*len(chs)\n",
        "bn[0]=False\n",
        "enc = Encoder(chs,bn)\n",
        "y = torch.cat([img.float().unsqueeze(0),img.float().unsqueeze(0)])\n",
        "print(y.shape)\n",
        "x,ftrs = enc(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LyvXq1qazB7"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, chs, dropout):\n",
        "    super().__init__()\n",
        "    self.dec_blocks = nn.ModuleList([UpSampleBlock(2*chs[i], chs[i+1],dropout[i]) for i in range(len(chs)-1)])\n",
        "    self.dec_blocks[0]=UpSampleBlock(chs[0],chs[1])\n",
        "  \n",
        "  def forward(self, x, encoder_features):\n",
        "    for block, ftr in zip(self.dec_blocks,encoder_features):\n",
        "        x = block(x)\n",
        "        x = torch.cat([x, ftr], dim=1)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldLwEsvgmTmi"
      },
      "outputs": [],
      "source": [
        "enc_chs = [3,64,128,256,512,512,512,512,512]\n",
        "enc_bn = [True]*len(chs)\n",
        "enc_bn[0]=False\n",
        "\n",
        "y = torch.cat([img.float().unsqueeze(0),img.float().unsqueeze(0)])\n",
        "dec_chs = enc_chs[::-1]\n",
        "dec_dropout = [False]*len(chs)\n",
        "dec_dropout[0:3]=[True]*3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bx0PBQMua1sV"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, enc_chs=enc_chs, enc_bn = enc_bn, dec_chs=dec_chs, dec_dropout=dec_dropout,lambdaa=100):\n",
        "    super().__init__()\n",
        "    self.encoder     = Encoder(enc_chs,enc_bn)\n",
        "    self.decoder     = Decoder(dec_chs,dec_dropout)\n",
        "    self.head        = nn.ConvTranspose2d(128,3, 4,stride=2, padding=1,bias=False)\n",
        "    nn.init.normal_(self.head.weight, mean=0.0, std=0.02)\n",
        "    self.head_act   = nn.Tanh()\n",
        "    self.lambdaa = lambdaa \n",
        "\n",
        "  def forward(self, x):\n",
        "    x, ftrs = self.encoder(x)\n",
        "    ftrs.reverse()\n",
        "    out      = self.decoder(x, ftrs[1:])\n",
        "    out      = self.head_act(self.head(out))\n",
        "    return out\n",
        "  \n",
        "  def get_loss(self,disc_out, gen_out, target):\n",
        "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "    gan_loss = loss_fn(disc_out,torch.ones_like(disc_out))\n",
        "    l1_loss = nn.L1Loss()(gen_out,target)\n",
        "    loss = gan_loss + self.lambdaa*l1_loss\n",
        "    return loss, gan_loss,l1_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QYTqRkY17Xf"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.down1 = DownSampleBlock(6,64,False)\n",
        "    self.down2 = DownSampleBlock(64,128,True)\n",
        "    self.down3 = DownSampleBlock(128,256,True)\n",
        "    self.down4 = DownSampleBlock(256,512,True,stride=1, padding=1)\n",
        "    self.conv = nn.Conv2d(512, 1, 4,stride=1, padding=1, bias=False)\n",
        "    nn.init.normal_(self.conv.weight, mean=0.0, std=0.02)\n",
        "    # self.out = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, input, target):\n",
        "    x = torch.cat([input,target],dim=1)\n",
        "    x =self.down1(x)\n",
        "    x= self.down2(x)\n",
        "    x = self.down3(x)\n",
        "    x = self.down4(x)\n",
        "    x = self.conv(x)\n",
        "    # x = self.out(x)\n",
        "    return x\n",
        "  \n",
        "  def get_loss(self, out, target):\n",
        "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "    loss = loss_fn(target,torch.ones_like(target))\n",
        "    loss+= loss_fn(out,torch.zeros_like(out))\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKm9U1a7bMw9"
      },
      "outputs": [],
      "source": [
        "gen = Generator()\n",
        "y1 = torch.cat([img.float().unsqueeze(0),img.float().unsqueeze(0)])\n",
        "y2 = torch.cat([real.float().unsqueeze(0),real.float().unsqueeze(0)])\n",
        "\n",
        "pred= gen(y1)\n",
        "print(pred.shape)\n",
        "\n",
        "dis = Discriminator()\n",
        "pred_dis = dis(y1, y2)\n",
        "print(pred_dis.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FC6Ap4j1TQbi"
      },
      "outputs": [],
      "source": [
        "gen_out = gen(y1)\n",
        "dis_real = dis(y1,y2)\n",
        "dis_gen = dis(y1,gen_out.detach())\n",
        "dis_loss = dis.get_loss(dis_real,dis_gen)\n",
        "print(dis_loss.item())\n",
        "gen_loss, gen_gan_loss, gen_l1_loss = gen.get_loss(dis_gen,gen_out,y2)\n",
        "print(gen_loss.item(),gen_gan_loss.item(),gen_l1_loss.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6b7EAHuDedV"
      },
      "outputs": [],
      "source": [
        "plt.imshow(y[0].permute(1, 2, 0)*0.5+0.5)\n",
        "plt.show()\n",
        "\n",
        "plt.imshow(pred[0].detach().permute(1, 2, 0)*0.5+0.5)\n",
        "plt.show()\n",
        "\n",
        "print(torch.max(pred[0]),torch.min(pred[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lCuIDNqTIqI"
      },
      "outputs": [],
      "source": [
        "train_data = CustomDataset(img_dir=\"data/facades\", data=\"train\", transform=True)\n",
        "test_data = CustomDataset(img_dir=\"data/facades\", data=\"test\", transform=True)\n",
        "\n",
        "train_dataloader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=16, shuffle=True)\n",
        "\n",
        "gen = Generator().to(device)\n",
        "dis = Discriminator().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYhrztQx7YT7"
      },
      "outputs": [],
      "source": [
        "# train_inp, train_tar = next(iter(train_dataloader))\n",
        "# test_inp, test_tar = next(iter(test_dataloader))\n",
        "\n",
        "# l = list(enumerate(train_dataloader))\n",
        "# len(l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V18pS8oxIR-j"
      },
      "outputs": [],
      "source": [
        "epochs = 300\n",
        "# start = time.time()\n",
        "\n",
        "gen_optim = torch.optim.Adam(gen.parameters(), lr=2e-4,betas=(0.5,0.999))\n",
        "dis_optim = torch.optim.Adam(dis.parameters(), lr=2e-4,betas=(0.5,0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1A0JbHRFi90M"
      },
      "outputs": [],
      "source": [
        "# from torch.utils.tensorboard import SummaryWriter\n",
        "# writer = SummaryWriter('runs/pix2pix')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yv5J6nZR2Qv"
      },
      "outputs": [],
      "source": [
        "def generate_images(model, test_input, tar,idx):\n",
        "  test_input=test_input.float()\n",
        "  prediction = model(test_input.to(device)).detach().cpu()\n",
        "  plt.figure(figsize=(15, 15))\n",
        "  \n",
        "  display_list = [test_input[idx], tar[idx], prediction[idx]]\n",
        "  title = ['Input Image', 'Ground Truth', 'Predicted Image']\n",
        "\n",
        "  for i in range(3):\n",
        "    plt.subplot(1, 3, i+1)\n",
        "    plt.title(title[i])\n",
        "    # Getting the pixel values in the [0, 1] range to plot.\n",
        "    plt.imshow((display_list[i] * 0.5 + 0.5).permute(1, 2, 0))\n",
        "    plt.axis('off')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MP2r-Wzm6JBY"
      },
      "outputs": [],
      "source": [
        "generate_images(gen, y1, y2,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nws58Ap8aaHp"
      },
      "outputs": [],
      "source": [
        "torch.autograd.set_detect_anomaly(True)\n",
        "for epoch in range(epochs):\n",
        "    running_loss = np.array([0,0,0,0],dtype=float)\n",
        "    for batch_idx, (inp,tar) in enumerate(train_dataloader):\n",
        "        # dis_optim.zero_grad()\n",
        "\n",
        "        inp,tar=inp.to(device),tar.to(device)\n",
        "        # dis.zero_grad()\n",
        "        # gen_out = gen(inp)\n",
        "        # dis_real = dis(inp,tar)\n",
        "        # dis_gen = dis(inp,gen_out.detach())\n",
        "        # dis_loss = dis.get_loss(dis_real,dis_gen)\n",
        "        # dis_loss.backward()\n",
        "        # dis_optim.step()\n",
        "\n",
        "        # gen.zero_grad()\n",
        "        # dis_gen = dis(inp,gen_out)\n",
        "        # gen_loss, gen_gan_loss, gen_l1_loss = gen.get_loss(dis_gen,gen_out,tar)\n",
        "        # gen_loss.backward()\n",
        "        # gen_optim.step()\n",
        "\n",
        "        b_size = inp.shape[0]\n",
        "        real_class = torch.ones(b_size,1,30,30).to(device)\n",
        "        fake_class = torch.zeros(b_size,1,30,30).to(device)\n",
        "\n",
        "        #Train D\n",
        "        dis.zero_grad()\n",
        "        real_patch = dis(inp,tar)\n",
        "        real_gan_loss= nn.BCEWithLogitsLoss()(real_patch,real_class)\n",
        "\n",
        "        fake=gen(inp)\n",
        "\n",
        "        fake_patch = dis(inp,fake.detach())\n",
        "        fake_gan_loss=nn.BCEWithLogitsLoss()(fake_patch,fake_class)\n",
        "\n",
        "        D_loss = real_gan_loss + fake_gan_loss\n",
        "        D_loss.backward()\n",
        "        dis_optim.step()\n",
        "\n",
        "        #Train G\n",
        "        gen.zero_grad()\n",
        "        fake_patch = dis(inp,fake)\n",
        "        fake_gan_loss=nn.BCEWithLogitsLoss()(fake_patch,real_class)\n",
        "\n",
        "        L1_loss = nn.L1Loss()(fake,tar)\n",
        "        G_loss = fake_gan_loss + 100*L1_loss\n",
        "        G_loss.backward()\n",
        "\n",
        "        gen_optim.step()\n",
        "\n",
        "        x= np.array([G_loss.item(),fake_gan_loss.item(),L1_loss.item(),D_loss.item()],dtype=float)\n",
        "        running_loss += x\n",
        "        if (batch_idx+1)%4==0:\n",
        "            print(\"Step:\",batch_idx+1,\"Gen loss:\",round(G_loss.item(),2),\"Gen GAN loss:\",round(fake_gan_loss.item(),2),\"Gen L1:\",round(L1_loss.item(),2),\"Dis loss:\",round(D_loss.item(),2))\n",
        "\n",
        "    n=(batch_idx+1)\n",
        "    running_loss=np.around(running_loss/n,decimals=2)\n",
        "    print(\"Epoch:\",epoch+1,\"Gen loss:\",running_loss[0],\"Gen GAN loss:\",running_loss[1],\"Gen L1:\",running_loss[2],\"Dis loss:\",running_loss[3])\n",
        "    if (epoch+1)%5==0: \n",
        "        generate_images(gen,y1,y2,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGmKBMeozofk"
      },
      "outputs": [],
      "source": [
        "torch.save(gen.state_dict(), 'PIX2PIX_GEN_500.ckpt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGkb7x7Wzofk"
      },
      "outputs": [],
      "source": [
        "torch.save(dis.state_dict(), 'PIX2PIX_DIS_500.ckpt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Uyg7h5AZzofk"
      },
      "outputs": [],
      "source": [
        "test_data = CustomDataset(img_dir=\"data/facades\", data=\"test\", transform=False)\n",
        "test_dataloader = DataLoader(test_data, batch_size=16, shuffle=True)\n",
        "test_inp, test_tar = next(iter(test_dataloader))\n",
        "\n",
        "for i in range(len(test_inp)):\n",
        "    generate_images(gen,test_inp,test_tar,i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2ueo2Zrzofl"
      },
      "outputs": [],
      "source": [
        "epochs = 200\n",
        "for epoch in range(epochs):\n",
        "    running_loss = np.array([0,0,0,0],dtype=float)\n",
        "    for batch_idx, (inp,tar) in enumerate(train_dataloader):\n",
        "        # dis_optim.zero_grad()\n",
        "\n",
        "        inp,tar=inp.to(device),tar.to(device)\n",
        "        # dis.zero_grad()\n",
        "        # gen_out = gen(inp)\n",
        "        # dis_real = dis(inp,tar)\n",
        "        # dis_gen = dis(inp,gen_out.detach())\n",
        "        # dis_loss = dis.get_loss(dis_real,dis_gen)\n",
        "        # dis_loss.backward()\n",
        "        # dis_optim.step()\n",
        "\n",
        "        # gen.zero_grad()\n",
        "        # dis_gen = dis(inp,gen_out)\n",
        "        # gen_loss, gen_gan_loss, gen_l1_loss = gen.get_loss(dis_gen,gen_out,tar)\n",
        "        # gen_loss.backward()\n",
        "        # gen_optim.step()\n",
        "\n",
        "        b_size = inp.shape[0]\n",
        "        real_class = torch.ones(b_size,1,30,30).to(device)\n",
        "        fake_class = torch.zeros(b_size,1,30,30).to(device)\n",
        "\n",
        "        #Train D\n",
        "        dis.zero_grad()\n",
        "        real_patch = dis(inp,tar)\n",
        "        real_gan_loss= nn.BCEWithLogitsLoss()(real_patch,real_class)\n",
        "\n",
        "        fake=gen(inp)\n",
        "\n",
        "        fake_patch = dis(inp,fake.detach())\n",
        "        fake_gan_loss=nn.BCEWithLogitsLoss()(fake_patch,fake_class)\n",
        "\n",
        "        D_loss = real_gan_loss + fake_gan_loss\n",
        "        D_loss.backward()\n",
        "        dis_optim.step()\n",
        "\n",
        "        #Train G\n",
        "        gen.zero_grad()\n",
        "        fake_patch = dis(inp,fake)\n",
        "        fake_gan_loss=nn.BCEWithLogitsLoss()(fake_patch,real_class)\n",
        "\n",
        "        L1_loss = nn.L1Loss()(fake,tar)\n",
        "        G_loss = fake_gan_loss + 100*L1_loss\n",
        "        G_loss.backward()\n",
        "\n",
        "        gen_optim.step()\n",
        "\n",
        "        x= np.array([G_loss.item(),fake_gan_loss.item(),L1_loss.item(),D_loss.item()],dtype=float)\n",
        "        running_loss += x\n",
        "        if (batch_idx+1)%4==0:\n",
        "            print(\"Step:\",batch_idx+1,\"Gen loss:\",round(G_loss.item(),2),\"Gen GAN loss:\",round(fake_gan_loss.item(),2),\"Gen L1:\",round(L1_loss.item(),2),\"Dis loss:\",round(D_loss.item(),2))\n",
        "\n",
        "    n=(batch_idx+1)\n",
        "    running_loss=np.around(running_loss/n,decimals=2)\n",
        "    print(\"Epoch:\",epoch+301,\"Gen loss:\",running_loss[0],\"Gen GAN loss:\",running_loss[1],\"Gen L1:\",running_loss[2],\"Dis loss:\",running_loss[3])\n",
        "    if (epoch+1)%5==0: \n",
        "        generate_images(gen,y1,y2,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rIQwiUt-Xt58"
      },
      "outputs": [],
      "source": [
        "test_data = CustomDataset(img_dir=\"data/facades\", data=\"test\", transform=False)\n",
        "test_dataloader = DataLoader(test_data, batch_size=16, shuffle=True)\n",
        "test_inp, test_tar = next(iter(test_dataloader))\n",
        "\n",
        "for i in range(len(test_inp)):\n",
        "    generate_images(gen,test_inp,test_tar,i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVdjnziWqr1l"
      },
      "outputs": [],
      "source": [
        "!ls\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This mounts your Google Drive to the Colab VM.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# TODO: Enter the foldername in your Drive where you have saved the unzipped\n",
        "# assignment folder, e.g. 'cs231n/assignments/assignment3/'\n",
        "FOLDERNAME = \"cs231n/\"\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "# Now that we've mounted your Drive, this ensures that\n",
        "# the Python interpreter of the Colab VM can load\n",
        "# python files from within it.\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
        "\n",
        "# This downloads the COCO dataset to your Drive\n",
        "# if it doesn't already exist.\n",
        "%cd /content/drive/My\\ Drive/$FOLDERNAME"
      ],
      "metadata": {
        "id": "jiC_xNtzwur5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(gen.state_dict(), 'PIX2PIX_GEN_500.ckpt')"
      ],
      "metadata": {
        "id": "l992pINhxIpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(dis.state_dict(), 'PIX2PIX_DIS_500.ckpt')"
      ],
      "metadata": {
        "id": "cAlUz3YexaFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NdrYYk4exf6F"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}